{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1668865060141,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "KGeEWGAWsevK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuVQUa8OsiFO"
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (784,)\n",
    "pop_size = 10\n",
    "generations = 5\n",
    "# l = [784, 500, 250, 100, 50]\n",
    "# l = [784, 500]\n",
    "# init = glorot_uniform(seed = 12)\n",
    "epochs_FineTune = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1668867745036,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "WVEUixlktiUC"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "batch_size = 32\n",
    "device = torch.device(\"cpu\")\n",
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1668865196275,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "AklGCw70smaN"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=data_path, train= True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=data_path, train= False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1668865445613,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "esUtJpU9smeM",
    "outputId": "a1f365f7-9384-4376-f697-a14aece1cd8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(  train_dataset[0][0].squeeze()  )\n",
    "print(train_dataset[0][1])\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668866606645,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "KwU9TzbxQ4Rn"
   },
   "outputs": [],
   "source": [
    "class TiedLinearLayer(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.param = nn.Parameter(torch.zeros(out, inp))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.param)\n",
    "\n",
    "    def forward(self, input, transpose):\n",
    "        if transpose is False:\n",
    "            output = F.linear(input, self.param)\n",
    "        else:\n",
    "            output = F.linear(input, self.param.t())\n",
    "        return output\n",
    "    \n",
    "class SingleTiedAutoEncoder(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.layers = TiedLinearLayer(inp,out)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1) \n",
    "        x = self.layers(x, transpose = False) \n",
    "        x = self.layers(x, transpose = True)\n",
    "        return x\n",
    "    \n",
    "class TiedAutoEncoder(nn.Module):\n",
    "    def __init__(self, shape_list, nonlinearity=torch.relu):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.shape_list = shape_list   \n",
    "        for i in range(len(self.shape_list)-1):\n",
    "            self.layers.append(TiedLinearLayer(self.shape_list[i],self.shape_list[i+1]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1) \n",
    "        #encode\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, transpose = False)\n",
    "            x = self.nonlinearity(x)\n",
    "        encoded_feats = x.detach().clone()\n",
    "        #decode\n",
    "        for i, layer in sorted( enumerate(self.layers), reverse=True ):\n",
    "            x = layer(x, transpose = True)\n",
    "            if i !=0: #if it's not the last layer\n",
    "                x = self.nonlinearity(x)\n",
    "        reconstructed_output = x\n",
    "        return encoded_feats, reconstructed_output\n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch, loss_fn=F.mse_loss):\n",
    "    model.train()\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        encoded_feats, reconstructed_output  = model(data)\n",
    "        target = torch.flatten(data, start_dim=1)\n",
    "        loss = loss_fn(reconstructed_output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "@torch.no_grad()\n",
    "def evaluate_loss(model, data_loader, device):\n",
    "    val_loss = 0\n",
    "    for data, _ in data_loader:\n",
    "        data = data.to(device)\n",
    "        _ , reconstructed_output  = model(data)\n",
    "        target = torch.flatten(data, start_dim=1)\n",
    "        loss = F.mse_loss(reconstructed_output, target)\n",
    "        val_loss += loss\n",
    "\n",
    "    validation_loss = val_loss/ len(data_loader)    \n",
    "    return validation_loss\n",
    "\n",
    "def layer_wise_train(model, device, train_loader, lr, epoch, loss_fn=F.mse_loss): \n",
    "#     shape_list = [784, 500, 250, 100, 50]\n",
    "    shape_list = model.shape_list\n",
    "    current_shape_list = []\n",
    "    weight_state_dict = {}\n",
    "\n",
    "    for layer_shape in shape_list:\n",
    "        current_shape_list.append(layer_shape)\n",
    "        if len(current_shape_list) < 2:\n",
    "            continue  \n",
    "        model = TiedAutoEncoder(current_shape_list, nonlinearity =torch.relu)\n",
    "        print(\"training .... \\n\", model)\n",
    "        #load prev weights \n",
    "        model.load_state_dict(weight_state_dict, strict=False)\n",
    "\n",
    "        #freeze network except last layer\n",
    "        for param in list(model.parameters())[:-1]:\n",
    "            param.requires_grad = False\n",
    "        #train the model\n",
    "        optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "        for epoch in range(1, epoch+1):\n",
    "            train(model, device, train_loader, optimizer, epoch, loss_fn)\n",
    "        #update weights\n",
    "        weight_state_dict = model.state_dict()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79505,
     "status": "ok",
     "timestamp": 1668869298106,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "aSjxW2fLQIpw",
    "outputId": "a35b6a20-b647-4295-cc1c-1705098d93fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.095326\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.058892\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.052115\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.042417\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.040422\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.037493\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.038556\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.038791\n"
     ]
    }
   ],
   "source": [
    "#simple training\n",
    "model = TiedAutoEncoder(shape_list = [784, 500, 250, 100, 50], nonlinearity =torch.relu)\n",
    "model = TiedAutoEncoder(shape_list = [784, 500], nonlinearity =torch.relu)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "for epoch in range(1, 5):\n",
    "    train(model, device, train_loader, optimizer, epoch, loss_fn = F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.096132\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.045417\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.037139\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.034012\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.032741\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.026232\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.025182\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.020832\n",
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "    (1): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.084084\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.042688\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.033100\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.031166\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.026675\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.028338\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.024939\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.022440\n",
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "    (1): TiedLinearLayer()\n",
      "    (2): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.088298\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.049240\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.047676\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.041865\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.039108\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.038623\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.038912\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.037650\n",
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "    (1): TiedLinearLayer()\n",
      "    (2): TiedLinearLayer()\n",
      "    (3): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.072085\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.056052\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.050296\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.046758\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.043278\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.044709\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.040352\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.043590\n"
     ]
    }
   ],
   "source": [
    "#layer-wise training \n",
    "lr = 0.05\n",
    "shape_list = [784, 500, 250, 100, 50]\n",
    "model = TiedAutoEncoder(shape_list, nonlinearity =torch.relu)\n",
    "layer_wise_train(model, device, train_loader, lr, epoch, loss_fn=F.mse_loss)    \n",
    "torch.save(model.state_dict(), \"./torchlogs/weihts_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticTiedAutoEncoder(TiedAutoEncoder):\n",
    "    def __init__(self, shape_list, nonlinearity=torch.relu):\n",
    "        super().__init__(shape_list, nonlinearity)\n",
    "        \n",
    "    @torch.no_grad()  \n",
    "    def crossover(self, parent, layer_key, p):\n",
    "        parent1 = self.state_dict()[layer_key]\n",
    "        parent2 = parent.state_dict()[layer_key]\n",
    "        assert parent1.shape == parent2.shape , \"shape of parents should match\"\n",
    "\n",
    "        weights_mask = torch.FloatTensor(parent1.shape).uniform_(0, 1) <= p\n",
    "        new_chromosome = parent1 * weights_mask + parent2 * weights_mask.logical_not()\n",
    "        \n",
    "        child = GeneticTiedAutoEncoder(self.shape_list, self.nonlinearity)\n",
    "        child.state_dict()[layer_key] = weights_mask  \n",
    "        return child\n",
    "        \n",
    "    @torch.no_grad()      \n",
    "    def mutation(self, layer_key, p):\n",
    "        chromosome = self.state_dict()[layer_key]\n",
    "        weights_mask = torch.FloatTensor(chromosome.shape).uniform_(0, 1) > p \n",
    "        self.state_dict()[layer_key] = chromosome * weights_mask  \n",
    "        \n",
    "def train_genetic_model(shape_list, pop_size, generations, prev_weights = {}, finetune_epoch=3, finetune_lr=0.01 , loss_fn=F.mse_loss):    \n",
    "    \n",
    "    #Generate choromosomes\n",
    "    print(\"\\nGenerated {0} models with {1} layer size! \".format(pop_size, shape_list))\n",
    "    models = [GeneticTiedAutoEncoder(shape_list, nonlinearity =torch.relu) for i in range(pop_size)]\n",
    "   \n",
    "    #Load prevoius layer weights\n",
    "    print()\n",
    "    if prev_weights != {}:\n",
    "        for model in models:\n",
    "             model.load_state_dict(prev_weights, strict=False)\n",
    "        shapes = []\n",
    "        for key_weight in prev_weights:\n",
    "            shapes.append(prev_weights[key_weight].shape)\n",
    "        print(\"\\nLoaded prevoius layer weights with shape {0}\".format(shapes))\n",
    "    \n",
    "    layer_key = next(reversed(models[0].state_dict())) #last layer key\n",
    "    print(\"\\nTraining {0} with shape of {1} : \".format(layer_key, models[0].state_dict()[layer_key].shape))\n",
    "    \n",
    "    for g in range(generations):     \n",
    "        print(\"\\nGeneration {0}: \\n\".format(g+1))\n",
    "        print(\"Calculating fitness for each chromosome...\")\n",
    "        #fitness\n",
    "        fitness = []\n",
    "        for model in models:\n",
    "            fitness.append( 1/evaluate_loss(model, train_loader, device))\n",
    "\n",
    "        #Select 5 best models (/choromosomes)\n",
    "        fit_arg = np.argsort(fitness) \n",
    "        selected_models = [models[f] for f in fit_arg[:pop_size//2]]\n",
    "        print(\"Selected {0} Top best chromosomes\".format(pop_size//2))\n",
    "        \n",
    "\n",
    "        #finetune selected models\n",
    "        print(\"Finetuning selected models...\\n\")\n",
    "        for model in selected_models:\n",
    "            #freeze network except the chromosome layer\n",
    "            for name, param in model.named_parameters():\n",
    "                if name == layer_key:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            #train the model\n",
    "            optimizer = optim.Adadelta(model.parameters(), lr=finetune_lr)\n",
    "            for epoch in range(1, finetune_epoch+1):\n",
    "                train(model, device, train_loader, optimizer, epoch, loss_fn)\n",
    "            \n",
    "\n",
    "        #cross over and mutation    \n",
    "        print(\"Generate {0} other chromosomes with Cross-Over and Mutation\\n\".format( pop_size//2))\n",
    "        for _ in range(pop_size//2):\n",
    "            mom_idx = np.random.randint(low=0, high=pop_size//2)\n",
    "            dad_idx = np.random.randint(low=0, high=pop_size//2)\n",
    "            child = selected_models[mom_idx].crossover(selected_models[dad_idx],layer_key, p=0.8)\n",
    "            child.mutation(layer_key, p=0.01)\n",
    "            selected_models.append(child)\n",
    "        models = selected_models\n",
    "        \n",
    "    fitness = []    \n",
    "    print(\"Selecting best chromosome as answer...\")\n",
    "    #fitness\n",
    "    for model in models:\n",
    "        fitness.append( 1/evaluate_loss(model, train_loader, device))\n",
    "    fit_arg = np.argsort(fitness) \n",
    "    best_model = models[fit_arg[-1]]\n",
    "    print(\"Finished\")\n",
    "    return best_model\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 10 models with [784, 500] layer size! \n",
      "\n",
      "\n",
      "Training layers.0.param with shape of torch.Size([500, 784]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n"
     ]
    }
   ],
   "source": [
    "shape_list = [784, 500, 200, 100]\n",
    "shape_list = [784, 500]\n",
    "pop_size = 10 \n",
    "generations = 2\n",
    "finetune_epoch = 0\n",
    "finetune_lr = 0.01\n",
    "prev_weights = {}\n",
    "\n",
    "model = train_genetic_model(shape_list, pop_size, generations, prev_weights, finetune_epoch, finetune_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerwise_genetic_train(shape_list, pop_size, generations, finetune_epoch=3, finetune_lr=0.01 , loss_fn=F.mse_loss):    \n",
    "    current_shape_list = []\n",
    "    weight_state_dict = {}\n",
    "\n",
    "    for layer_shape in shape_list:\n",
    "        current_shape_list.append(layer_shape)\n",
    "        if len(current_shape_list) < 2:\n",
    "            continue  \n",
    "        model = train_genetic_model(current_shape_list, pop_size, generations, weight_state_dict, finetune_epoch, finetune_lr , loss_fn)\n",
    "        weight_state_dict = model.state_dict()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 10 models with [784, 20] layer size! \n",
      "\n",
      "\n",
      "Training layers.0.param with shape of torch.Size([20, 784]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n",
      "\n",
      "Generated 10 models with [784, 20, 10] layer size! \n",
      "\n",
      "\n",
      "Loaded prevoius layer weights with shape [torch.Size([20, 784])]\n",
      "\n",
      "Training layers.1.param with shape of torch.Size([10, 20]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n",
      "\n",
      "Generated 10 models with [784, 20, 10, 5] layer size! \n",
      "\n",
      "\n",
      "Loaded prevoius layer weights with shape [torch.Size([20, 784]), torch.Size([10, 20])]\n",
      "\n",
      "Training layers.2.param with shape of torch.Size([5, 10]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n",
      "\n",
      "Generated 10 models with [784, 20, 10, 5, 1] layer size! \n",
      "\n",
      "\n",
      "Loaded prevoius layer weights with shape [torch.Size([20, 784]), torch.Size([10, 20]), torch.Size([5, 10])]\n",
      "\n",
      "Training layers.3.param with shape of torch.Size([1, 5]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "shape_list = [784, 20, 10 , 5 , 1]\n",
    "pop_size = 10 \n",
    "generations = 2\n",
    "finetune_epoch = 0\n",
    "finetune_lr = 0.01\n",
    "\n",
    "model = layerwise_genetic_train(shape_list, pop_size, generations, finetune_epoch, finetune_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers.0.param',\n",
       "              tensor([[ 0.0137,  0.0761,  0.0135,  ..., -0.0536, -0.0801, -0.0638],\n",
       "                      [ 0.0538,  0.0290,  0.0854,  ...,  0.0671,  0.0539,  0.0672],\n",
       "                      [-0.0431,  0.0670, -0.0195,  ..., -0.0513,  0.0081, -0.0265],\n",
       "                      ...,\n",
       "                      [-0.0770, -0.0229, -0.0062,  ..., -0.0327,  0.0650,  0.0297],\n",
       "                      [ 0.0336,  0.0847,  0.0549,  ...,  0.0701,  0.0686,  0.0129],\n",
       "                      [-0.0076, -0.0216,  0.0128,  ..., -0.0231, -0.0602,  0.0794]])),\n",
       "             ('layers.1.param',\n",
       "              tensor([[ 3.8953e-01,  4.3208e-01, -2.1330e-01,  2.5092e-01, -2.6866e-01,\n",
       "                       -1.2396e-01, -2.6251e-01,  1.4670e-01, -4.7284e-02,  2.6237e-01,\n",
       "                       -7.3860e-02,  2.6181e-01, -3.8059e-01,  3.4638e-01,  1.5986e-01,\n",
       "                        2.2921e-01, -1.0531e-01, -9.7630e-02, -6.3520e-02,  1.7616e-01],\n",
       "                      [ 2.4162e-01,  3.3896e-01,  1.2955e-01,  2.5579e-01, -2.7832e-01,\n",
       "                        2.3569e-01,  4.2847e-01, -1.0817e-01, -1.5199e-01, -4.8940e-02,\n",
       "                        2.6357e-01,  8.5491e-02, -9.4958e-03,  9.8267e-02, -1.0802e-01,\n",
       "                        3.7492e-01, -1.1139e-01, -1.7346e-01, -8.5193e-02,  4.2377e-01],\n",
       "                      [ 2.2192e-01, -3.0862e-01, -1.5074e-01,  5.0743e-02,  3.1661e-01,\n",
       "                       -3.2413e-01,  7.0713e-02,  3.5258e-01, -1.3258e-01, -3.0850e-01,\n",
       "                       -4.0079e-01,  1.0263e-01,  2.3774e-01,  2.0998e-02, -8.4949e-02,\n",
       "                        3.2207e-01, -3.8206e-01,  4.3462e-01,  6.7598e-02, -8.6990e-02],\n",
       "                      [ 4.3380e-04,  2.8405e-01, -4.4004e-01, -2.2825e-01, -1.9708e-01,\n",
       "                       -1.2874e-01,  1.0430e-01, -2.7644e-01, -1.2602e-01,  6.2884e-03,\n",
       "                       -3.3977e-01,  4.4389e-01, -3.1201e-01, -5.0443e-02, -2.3212e-01,\n",
       "                       -1.1786e-01, -1.1337e-01, -4.0633e-01,  3.0618e-02, -9.3670e-02],\n",
       "                      [-3.9116e-01,  2.0632e-03,  2.8734e-01,  3.6002e-01, -2.4607e-03,\n",
       "                        3.5907e-01, -9.2476e-02,  4.2301e-01,  1.5236e-01,  3.7319e-01,\n",
       "                        3.6289e-01, -9.7459e-02,  8.0453e-02,  1.5797e-01, -3.5610e-01,\n",
       "                        4.2684e-01, -7.1220e-02, -1.2906e-01, -2.0982e-01, -4.1172e-01],\n",
       "                      [ 4.0901e-01, -3.4954e-02,  2.8301e-01,  2.4077e-01,  2.1493e-01,\n",
       "                        4.4229e-01, -2.2678e-01,  2.9871e-01,  2.2813e-01,  3.0914e-01,\n",
       "                        3.9629e-01,  2.4329e-01, -1.0033e-01, -7.7229e-02, -4.2251e-01,\n",
       "                       -4.1355e-02, -3.4484e-01,  3.0906e-01, -1.1339e-01, -3.6442e-01],\n",
       "                      [-1.6802e-01,  7.8472e-02,  5.3704e-02,  3.3907e-01, -3.1997e-01,\n",
       "                       -5.3976e-02,  2.3036e-03, -2.6462e-01, -4.2505e-01, -3.1119e-01,\n",
       "                        3.5743e-01,  1.6758e-01,  9.9718e-02,  2.0995e-01,  1.5319e-01,\n",
       "                        5.1779e-02, -1.0956e-01,  4.3608e-01,  2.7542e-01, -1.1624e-01],\n",
       "                      [ 1.4009e-01,  7.7461e-02, -1.6574e-02, -2.2710e-01,  4.2490e-01,\n",
       "                        3.8384e-01,  3.7866e-01, -4.2656e-01,  2.1949e-02, -3.1827e-02,\n",
       "                        1.1597e-02,  2.6302e-01, -6.3637e-02, -1.5335e-01,  2.2011e-01,\n",
       "                       -6.8686e-02,  7.4712e-02, -3.5688e-01,  3.9821e-01, -2.3726e-03],\n",
       "                      [ 9.5555e-02,  4.6020e-02,  2.8536e-01, -3.5303e-01, -3.0593e-01,\n",
       "                       -1.8553e-02, -3.8755e-01,  3.7472e-01,  3.3995e-01,  3.8508e-01,\n",
       "                       -2.9461e-01, -3.4043e-02, -2.0183e-01,  2.0644e-01, -3.7972e-02,\n",
       "                        8.1069e-02,  2.2670e-01, -1.5739e-01, -3.1594e-01, -1.5294e-02],\n",
       "                      [-1.0679e-01,  2.6468e-01, -3.7584e-01, -3.0645e-01, -3.1246e-02,\n",
       "                       -3.2337e-01,  4.4012e-01,  2.4511e-01,  4.2811e-01, -2.5461e-02,\n",
       "                       -3.8825e-01, -9.6302e-02, -3.8456e-01,  2.2627e-01,  3.3144e-01,\n",
       "                       -3.7408e-01,  3.6926e-01, -3.1036e-01, -3.8861e-01, -5.8849e-02]])),\n",
       "             ('layers.2.param',\n",
       "              tensor([[ 0.4396,  0.4681, -0.0699, -0.2237,  0.5400,  0.1509, -0.2713, -0.3000,\n",
       "                       -0.3880, -0.3609],\n",
       "                      [-0.3252, -0.3305, -0.0403,  0.3329, -0.4223,  0.5173, -0.4975,  0.4239,\n",
       "                       -0.0202,  0.3835],\n",
       "                      [-0.4987, -0.1563,  0.2889,  0.4155, -0.3234,  0.4173,  0.5666,  0.6315,\n",
       "                       -0.0243, -0.3768],\n",
       "                      [ 0.1686, -0.1307, -0.4079,  0.0606,  0.5405,  0.5797, -0.0799,  0.3345,\n",
       "                       -0.3117,  0.1612],\n",
       "                      [ 0.3558, -0.4805, -0.4266, -0.2799, -0.4694,  0.2297,  0.3510, -0.2616,\n",
       "                        0.0236, -0.2395]])),\n",
       "             ('layers.3.param',\n",
       "              tensor([[ 0.6238,  0.8500, -0.9458, -0.3330, -0.1708]]))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1668869734087,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "aw82dI0sM-xE",
    "outputId": "0f80f5c6-9471-4f65-cbcd-afd971d2706c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAKYElEQVR4nO3dX+jdd33H8edrbZpidJDoFkIt00kZlMGi/MgGluHolNqb1BsxF5JB4eeFBQUvLO7CXpYxlV0MIa7BbLjKQEtzUTazIBRhlP5asjZtnaklYkKaTHphHSxN63sXv2/lZ/v75ffrOd/zh72fDzicc77f88v3zaHPnnO+58AnVYWk//9+Z9EDSJoPY5eaMHapCWOXmjB2qYkb53mwm7K7bmbPPA8ptfK//A+v1dVstm+q2JPcBfwdcAPwD1X14PUefzN7+NPcOc0hJV3HE3V6y30Tv41PcgPw98AngduBI0lun/TfkzRb03xmPwS8WFUvVdVrwHeBw+OMJWls08R+C/DzDfcvDNt+S5LVJGtJ1q5xdYrDSZrGzM/GV9WxqlqpqpVd7J714SRtYZrYLwK3brj//mGbpCU0TexPArcl+WCSm4DPACfHGUvS2Cb+6q2qXk9yH/BvrH/1dryqnhttMkmjmup79qp6DHhspFkkzZA/l5WaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqmJqZZsTnIeeBV4A3i9qlbGGErS+KaKffAXVfWLEf4dSTPk23ipiWljL+AHSZ5KsrrZA5KsJllLsnaNq1MeTtKkpn0bf0dVXUzy+8CpJD+uqsc3PqCqjgHHAH43+2rK40ma0FSv7FV1cbi+AjwCHBpjKEnjmzj2JHuSvOfN28AngLNjDSZpXNO8jd8PPJLkzX/nn6vqX0eZStLoJo69ql4C/mTEWSTNkF+9SU0Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71MS2sSc5nuRKkrMbtu1LcirJueF672zHlDStnbyyfxu46y3b7gdOV9VtwOnhvqQltm3sVfU48MpbNh8GTgy3TwD3jDyXpJHdOOHf7a+qS8Ptl4H9Wz0wySqwCnAz75rwcJKmNfUJuqoqoK6z/1hVrVTVyi52T3s4SROaNPbLSQ4ADNdXxhtJ0ixMGvtJ4Ohw+yjw6DjjSJqVnXz19jDwH8AfJbmQ5F7gQeDjSc4Bfzncl7TEtj1BV1VHtth158izSJohf0EnNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSEztZn/14kitJzm7Y9kCSi0nODJe7ZzumpGnt5JX928Bdm2z/RlUdHC6PjTuWpLFtG3tVPQ68ModZJM3QNJ/Z70vyzPA2f+9WD0qymmQtydo1rk5xOEnTmDT2bwIfAg4Cl4CvbfXAqjpWVStVtbKL3RMeTtK0Joq9qi5X1RtV9WvgW8ChcceSNLaJYk9yYMPdTwFnt3qspOVw43YPSPIw8DHgfUkuAF8FPpbkIFDAeeBzM5xR0gi2jb2qjmyy+aEZzCJphvwFndSEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS01sG3uSW5P8MMnzSZ5L8oVh+74kp5KcG673zn5cSZPaySv768CXqup24M+Azye5HbgfOF1VtwGnh/uSltS2sVfVpap6erj9KvACcAtwGDgxPOwEcM+shpQ0vRvfyYOTfAD4MPAEsL+qLg27Xgb2b/E3q8AqwM28a9I5JU1pxyfokrwb+B7wxar65cZ9VVVAbfZ3VXWsqlaqamUXu6caVtLkdhR7kl2sh/6dqvr+sPlykgPD/gPAldmMKGkMOzkbH+Ah4IWq+vqGXSeBo8Pto8Cj448naSw7+cz+UeCzwLNJzgzbvgI8CPxLknuBnwGfns2IksawbexV9SMgW+y+c9xxJM2Kv6CTmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5ea2Mn67Lcm+WGS55M8l+QLw/YHklxMcma43D37cSVNaifrs78OfKmqnk7yHuCpJKeGfd+oqr+d3XiSxrKT9dkvAZeG268meQG4ZdaDSRrXO/rMnuQDwIeBJ4ZN9yV5JsnxJHu3+JvVJGtJ1q5xdaphJU1ux7EneTfwPeCLVfVL4JvAh4CDrL/yf22zv6uqY1W1UlUru9g9wsiSJrGj2JPsYj3071TV9wGq6nJVvVFVvwa+BRya3ZiSprWTs/EBHgJeqKqvb9h+YMPDPgWcHX88SWPZydn4jwKfBZ5NcmbY9hXgSJKDQAHngc/NZEJJo9jJ2fgfAdlk12PjjyNpVvwFndSEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNpKrmd7Dkv4Gfbdj0PuAXcxvgnVnW2ZZ1LnC2SY052x9U1e9ttmOusb/t4MlaVa0sbIDrWNbZlnUucLZJzWs238ZLTRi71MSiYz+24ONfz7LOtqxzgbNNai6zLfQzu6T5WfQru6Q5MXapiYXEnuSuJP+V5MUk9y9ihq0kOZ/k2WEZ6rUFz3I8yZUkZzds25fkVJJzw/Wma+wtaLalWMb7OsuML/S5W/Ty53P/zJ7kBuAnwMeBC8CTwJGqen6ug2whyXlgpaoW/gOMJH8O/Ar4x6r642Hb3wCvVNWDw/8o91bVl5dktgeAXy16Ge9htaIDG5cZB+4B/ooFPnfXmevTzOF5W8Qr+yHgxap6qapeA74LHF7AHEuvqh4HXnnL5sPAieH2Cdb/Y5m7LWZbClV1qaqeHm6/Cry5zPhCn7vrzDUXi4j9FuDnG+5fYLnWey/gB0meSrK66GE2sb+qLg23Xwb2L3KYTWy7jPc8vWWZ8aV57iZZ/nxanqB7uzuq6iPAJ4HPD29Xl1KtfwZbpu9Od7SM97xsssz4byzyuZt0+fNpLSL2i8CtG+6/f9i2FKrq4nB9BXiE5VuK+vKbK+gO11cWPM9vLNMy3pstM84SPHeLXP58EbE/CdyW5INJbgI+A5xcwBxvk2TPcOKEJHuAT7B8S1GfBI4Ot48Cjy5wlt+yLMt4b7XMOAt+7ha+/HlVzf0C3M36GfmfAn+9iBm2mOsPgf8cLs8tejbgYdbf1l1j/dzGvcB7gdPAOeDfgX1LNNs/Ac8Cz7Ae1oEFzXYH62/RnwHODJe7F/3cXWeuuTxv/lxWasITdFITxi41YexSE8YuNWHsUhPGLjVh7FIT/wd9DjwtgfVGWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_sample = train_dataset[2][0]\n",
    "plt.imshow(data_sample.squeeze())\n",
    "plt.show()\n",
    "encoded_feats, reconstructed_output = model(data_sample)\n",
    "# reconstructed_output = model(data_sample)\n",
    "plt.imshow(reconstructed_output.detach().numpy().reshape(28,28) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5sJXR6lRTwdohVK8osUWX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
