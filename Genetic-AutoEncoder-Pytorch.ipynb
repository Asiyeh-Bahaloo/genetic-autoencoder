{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1668865060141,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "KGeEWGAWsevK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuVQUa8OsiFO"
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (784,)\n",
    "pop_size = 10\n",
    "generations = 5\n",
    "# l = [784, 500, 250, 100, 50]\n",
    "# l = [784, 500]\n",
    "# init = glorot_uniform(seed = 12)\n",
    "epochs_FineTune = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1668867745036,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "WVEUixlktiUC"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "batch_size = 32\n",
    "device = torch.device(\"cpu\")\n",
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1668865196275,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "AklGCw70smaN"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=data_path, train= True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=data_path, train= False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1668865445613,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "esUtJpU9smeM",
    "outputId": "a1f365f7-9384-4376-f697-a14aece1cd8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAOZ0lEQVR4nO3dbYxc5XnG8euKbezamMQbB9chLjjgFAg0Jl0ZEBZQobgOqgSoCsSKIkJpnSY4Ca0rQWlV3IpWbpUQUUqRTHExFS+BBIQ/0CTUQpCowWWhBgwEDMY0NmaNWYENIX5Z3/2w42iBnWeXmTMv3vv/k1Yzc+45c24NXD5nznNmHkeEAIx/H+p0AwDag7ADSRB2IAnCDiRB2IEkJrZzY4d5ckzRtHZuEkjlV3pbe2OPR6o1FXbbiyVdJ2mCpH+LiJWl50/RNJ3qc5rZJICC9bGubq3hw3jbEyTdIOnzkk6UtMT2iY2+HoDWauYz+wJJL0TE5ojYK+lOSedV0xaAqjUT9qMk/WLY4621Ze9ie6ntPtt9+7Snic0BaEbLz8ZHxKqI6I2I3kma3OrNAaijmbBvkzRn2ONP1JYB6ELNhP1RSfNsz7V9mKQvSlpbTVsAqtbw0FtE7Le9TNKPNDT0tjoinq6sMwCVamqcPSLul3R/Rb0AaCEulwWSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJpmZxRffzxPJ/4gkfm9nS7T/3F8fUrQ1OPVBc9+hjdxTrU7/uYv3Vaw+rW3u893vFdXcOvl2sn3r38mL9uD9/pFjvhKbCbnuLpN2SBiXtj4jeKpoCUL0q9uy/FxE7K3gdAC3EZ3YgiWbDHpJ+bPsx20tHeoLtpbb7bPft054mNwegUc0exi+MiG22j5T0gO2fR8TDw58QEaskrZKkI9wTTW4PQIOa2rNHxLba7Q5J90paUEVTAKrXcNhtT7M9/eB9SYskbayqMQDVauYwfpake20ffJ3bI+KHlXQ1zkw4YV6xHpMnFeuvnPWRYv2d0+qPCfd8uDxe/JPPlMebO+k/fzm9WP/Hf1lcrK8/+fa6tZf2vVNcd2X/54r1j//k0PtE2nDYI2KzpM9U2AuAFmLoDUiCsANJEHYgCcIOJEHYgST4imsFBs/+bLF+7S03FOufmlT/q5jj2b4YLNb/5vqvFOsT3y4Pf51+97K6tenb9hfXnbyzPDQ3tW99sd6N2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs1dg8nOvFOuP/WpOsf6pSf1VtlOp5dtPK9Y3v1X+Kepbjv1+3dqbB8rj5LP++b+L9VY69L7AOjr27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhCPaN6J4hHviVJ/Ttu11i4FLTi/Wdy0u/9zzhCcPL9af+Pr1H7ing67Z+TvF+qNnlcfRB994s1iP0+v/APGWbxZX1dwlT5SfgPdZH+u0KwZGnMuaPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exeYMPOjxfrg6wPF+ku31x8rf/rM1cV1F/zDN4r1I2/o3HfK8cE1Nc5ue7XtHbY3DlvWY/sB25tqtzOqbBhA9cZyGH+LpPfOen+lpHURMU/SutpjAF1s1LBHxMOS3nsceZ6kNbX7aySdX3FfACrW6G/QzYqI7bX7r0qaVe+JtpdKWipJUzS1wc0BaFbTZ+Nj6Axf3bN8EbEqInojoneSJje7OQANajTs/bZnS1Ltdkd1LQFohUbDvlbSxbX7F0u6r5p2ALTKqJ/Zbd8h6WxJM21vlXS1pJWS7rJ9qaSXJV3YyibHu8Gdrze1/r5djc/v/ukvPVOsv3bjhPILHCjPsY7uMWrYI2JJnRJXxwCHEC6XBZIg7EAShB1IgrADSRB2IAmmbB4HTrji+bq1S04uD5r8+9HrivWzvnBZsT79e48U6+ge7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ceB0rTJr3/thOK6/7f2nWL9ymtuLdb/8sILivX43w/Xrc35+58V11Ubf+Y8A/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEUzYnN/BHpxfrt1397WJ97sQpDW/707cuK9bn3bS9WN+/eUvD2x6vmpqyGcD4QNiBJAg7kARhB5Ig7EAShB1IgrADSTDOjqI4Y36xfsTKrcX6HZ/8UcPbPv7BPy7Wf/tv63+PX5IGN21ueNuHqqbG2W2vtr3D9sZhy1bY3mZ7Q+3v3CobBlC9sRzG3yJp8QjLvxsR82t/91fbFoCqjRr2iHhY0kAbegHQQs2coFtm+8naYf6Mek+yvdR2n+2+fdrTxOYANKPRsN8o6VhJ8yVtl/Sdek+MiFUR0RsRvZM0ucHNAWhWQ2GPiP6IGIyIA5JukrSg2rYAVK2hsNuePezhBZI21nsugO4w6ji77TsknS1ppqR+SVfXHs+XFJK2SPpqRJS/fCzG2cejCbOOLNZfuei4urX1V1xXXPdDo+yLvvTSomL9zYWvF+vjUWmcfdRJIiJiyQiLb266KwBtxeWyQBKEHUiCsANJEHYgCcIOJMFXXNExd20tT9k81YcV67+MvcX6H3zj8vqvfe/64rqHKn5KGgBhB7Ig7EAShB1IgrADSRB2IAnCDiQx6rfekNuBheWfkn7xC+Upm0+av6VubbRx9NFcP3BKsT71vr6mXn+8Yc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj7OufekYv35b5bHum86Y02xfuaU8nfKm7En9hXrjwzMLb/AgVF/3TwV9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7IeAiXOPLtZfvOTjdWsrLrqzuO4fHr6zoZ6qcFV/b7H+0HWnFesz1pR/dx7vNuqe3fYc2w/afsb207a/VVveY/sB25tqtzNa3y6ARo3lMH6/pOURcaKk0yRdZvtESVdKWhcR8yStqz0G0KVGDXtEbI+Ix2v3d0t6VtJRks6TdPBayjWSzm9VkwCa94E+s9s+RtIpktZLmhURBy8+flXSrDrrLJW0VJKmaGqjfQJo0pjPxts+XNIPJF0eEbuG12JodsgRZ4iMiFUR0RsRvZM0ualmATRuTGG3PUlDQb8tIu6pLe63PbtWny1pR2taBFCFUQ/jbVvSzZKejYhrh5XWSrpY0sra7X0t6XAcmHjMbxXrb/7u7GL9or/7YbH+px+5p1hvpeXby8NjP/vX+sNrPbf8T3HdGQcYWqvSWD6znyHpy5Kesr2htuwqDYX8LtuXSnpZ0oWtaRFAFUYNe0T8VNKIk7tLOqfadgC0CpfLAkkQdiAJwg4kQdiBJAg7kARfcR2jibN/s25tYPW04rpfm/tQsb5ken9DPVVh2baFxfrjN5anbJ75/Y3Fes9uxsq7BXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUgizTj73t8v/2zx3j8bKNavOu7+urVFv/F2Qz1VpX/wnbq1M9cuL657/F//vFjveaM8Tn6gWEU3Yc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkGWffcn7537XnT767Zdu+4Y1ji/XrHlpUrHuw3o/7Djn+mpfq1ub1ry+uO1isYjxhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTgiyk+w50i6VdIsSSFpVURcZ3uFpD+R9FrtqVdFRP0vfUs6wj1xqpn4FWiV9bFOu2JgxAszxnJRzX5JyyPicdvTJT1m+4Fa7bsR8e2qGgXQOmOZn327pO21+7ttPyvpqFY3BqBaH+gzu+1jJJ0i6eA1mMtsP2l7te0ZddZZarvPdt8+7WmqWQCNG3PYbR8u6QeSLo+IXZJulHSspPka2vN/Z6T1ImJVRPRGRO8kTa6gZQCNGFPYbU/SUNBvi4h7JCki+iNiMCIOSLpJ0oLWtQmgWaOG3bYl3Szp2Yi4dtjy2cOedoGk8nSeADpqLGfjz5D0ZUlP2d5QW3aVpCW252toOG6LpK+2pEMAlRjL2fifShpp3K44pg6gu3AFHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlRf0q60o3Zr0l6ediimZJ2tq2BD6Zbe+vWviR6a1SVvR0dER8bqdDWsL9v43ZfRPR2rIGCbu2tW/uS6K1R7eqNw3ggCcIOJNHpsK/q8PZLurW3bu1LordGtaW3jn5mB9A+nd6zA2gTwg4k0ZGw215s+znbL9i+shM91GN7i+2nbG+w3dfhXlbb3mF747BlPbYfsL2pdjviHHsd6m2F7W21926D7XM71Nsc2w/afsb207a/VVve0feu0Fdb3re2f2a3PUHS85I+J2mrpEclLYmIZ9raSB22t0jqjYiOX4Bh+0xJb0m6NSJOqi37J0kDEbGy9g/ljIi4okt6WyHprU5P412brWj28GnGJZ0v6Svq4HtX6OtCteF968SefYGkFyJic0TslXSnpPM60EfXi4iHJQ28Z/F5ktbU7q/R0P8sbVent64QEdsj4vHa/d2SDk4z3tH3rtBXW3Qi7EdJ+sWwx1vVXfO9h6Qf237M9tJONzOCWRGxvXb/VUmzOtnMCEadxrud3jPNeNe8d41Mf94sTtC938KI+Kykz0u6rHa42pVi6DNYN42djmka73YZYZrxX+vke9fo9OfN6kTYt0maM+zxJ2rLukJEbKvd7pB0r7pvKur+gzPo1m53dLifX+umabxHmmZcXfDedXL6806E/VFJ82zPtX2YpC9KWtuBPt7H9rTaiRPZniZpkbpvKuq1ki6u3b9Y0n0d7OVdumUa73rTjKvD713Hpz+PiLb/STpXQ2fkX5T0V53ooU5fn5T0RO3v6U73JukODR3W7dPQuY1LJX1U0jpJmyT9l6SeLurtPyQ9JelJDQVrdod6W6ihQ/QnJW2o/Z3b6feu0Fdb3jculwWS4AQdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(  train_dataset[0][0].squeeze()  )\n",
    "print(train_dataset[0][1])\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1668866606645,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "KwU9TzbxQ4Rn"
   },
   "outputs": [],
   "source": [
    "class TiedLinearLayer(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.param = nn.Parameter(torch.zeros(out, inp))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.param)\n",
    "\n",
    "    def forward(self, input, transpose):\n",
    "        if transpose is False:\n",
    "            output = F.linear(input, self.param)\n",
    "        else:\n",
    "            output = F.linear(input, self.param.t())\n",
    "        return output\n",
    "    \n",
    "class SingleTiedAutoEncoder(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.layers = TiedLinearLayer(inp,out)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1) \n",
    "        x = self.layers(x, transpose = False) \n",
    "        x = self.layers(x, transpose = True)\n",
    "        return x\n",
    "    \n",
    "class TiedAutoEncoder(nn.Module):\n",
    "    def __init__(self, shape_list, nonlinearity=torch.relu):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.shape_list = shape_list   \n",
    "        for i in range(len(self.shape_list)-1):\n",
    "            self.layers.append(TiedLinearLayer(self.shape_list[i],self.shape_list[i+1]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1) \n",
    "        #encode\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, transpose = False)\n",
    "            x = self.nonlinearity(x)\n",
    "        encoded_feats = x.detach().clone()\n",
    "        #decode\n",
    "        for i, layer in sorted( enumerate(self.layers), reverse=True ):\n",
    "            x = layer(x, transpose = True)\n",
    "            if i !=0: #if it's not the last layer\n",
    "                x = self.nonlinearity(x)\n",
    "        reconstructed_output = x\n",
    "        return encoded_feats, reconstructed_output\n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch, loss_fn=F.mse_loss):\n",
    "    model.train()\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        encoded_feats, reconstructed_output  = model(data)\n",
    "        target = torch.flatten(data, start_dim=1)\n",
    "        loss = loss_fn(reconstructed_output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "@torch.no_grad()\n",
    "def evaluate_loss(model, data_loader, device):\n",
    "    val_loss = 0\n",
    "    for data, _ in data_loader:\n",
    "        data = data.to(device)\n",
    "        _ , reconstructed_output  = model(data)\n",
    "        target = torch.flatten(data, start_dim=1)\n",
    "        loss = F.mse_loss(reconstructed_output, target)\n",
    "        val_loss += loss\n",
    "\n",
    "    validation_loss = val_loss/ len(data_loader)    \n",
    "    return validation_loss\n",
    "\n",
    "def layer_wise_train(model, device, train_loader, lr, epoch, loss_fn=F.mse_loss): \n",
    "#     shape_list = [784, 500, 250, 100, 50]\n",
    "    shape_list = model.shape_list\n",
    "    current_shape_list = []\n",
    "    weight_state_dict = {}\n",
    "\n",
    "    for layer_shape in shape_list:\n",
    "        current_shape_list.append(layer_shape)\n",
    "        if len(current_shape_list) < 2:\n",
    "            continue  \n",
    "        model = TiedAutoEncoder(current_shape_list, nonlinearity =torch.relu)\n",
    "        print(\"training .... \\n\", model)\n",
    "        #load prev weights \n",
    "        model.load_state_dict(weight_state_dict, strict=False)\n",
    "\n",
    "        #freeze network except last layer\n",
    "        for param in list(model.parameters())[:-1]:\n",
    "            param.requires_grad = False\n",
    "        #train the model\n",
    "        optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "        for epoch in range(1, epoch+1):\n",
    "            train(model, device, train_loader, optimizer, epoch, loss_fn)\n",
    "        #update weights\n",
    "        weight_state_dict = model.state_dict()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79505,
     "status": "ok",
     "timestamp": 1668869298106,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "aSjxW2fLQIpw",
    "outputId": "a35b6a20-b647-4295-cc1c-1705098d93fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.095326\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.058892\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.052115\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.042417\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.040422\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.037493\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.038556\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.038791\n"
     ]
    }
   ],
   "source": [
    "#simple training\n",
    "model = TiedAutoEncoder(shape_list = [784, 500, 250, 100, 50], nonlinearity =torch.relu)\n",
    "model = TiedAutoEncoder(shape_list = [784, 500], nonlinearity =torch.relu)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "for epoch in range(1, 5):\n",
    "    train(model, device, train_loader, optimizer, epoch, loss_fn = F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.096132\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.045417\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.037139\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.034012\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.032741\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.026232\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.025182\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.020832\n",
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "    (1): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.084084\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.042688\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.033100\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.031166\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.026675\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.028338\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.024939\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.022440\n",
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "    (1): TiedLinearLayer()\n",
      "    (2): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.088298\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.049240\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.047676\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.041865\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.039108\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.038623\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.038912\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.037650\n",
      "training .... \n",
      " TiedAutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): TiedLinearLayer()\n",
      "    (1): TiedLinearLayer()\n",
      "    (2): TiedLinearLayer()\n",
      "    (3): TiedLinearLayer()\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.072085\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.056052\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.050296\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.046758\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.043278\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.044709\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.040352\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.043590\n"
     ]
    }
   ],
   "source": [
    "#layer-wise training \n",
    "lr = 0.05\n",
    "shape_list = [784, 500, 250, 100, 50]\n",
    "model = TiedAutoEncoder(shape_list, nonlinearity =torch.relu)\n",
    "layer_wise_train(model, device, train_loader, lr, epoch, loss_fn=F.mse_loss)    \n",
    "torch.save(model.state_dict(), \"./torchlogs/weihts_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticTiedAutoEncoder(TiedAutoEncoder):\n",
    "    def __init__(self, shape_list, nonlinearity=torch.relu):\n",
    "        super().__init__(shape_list, nonlinearity)\n",
    "        \n",
    "    @torch.no_grad()  \n",
    "    def crossover(self, parent, layer_key, p):\n",
    "        parent1 = self.state_dict()[layer_key]\n",
    "        parent2 = parent.state_dict()[layer_key]\n",
    "        assert parent1.shape == parent2.shape , \"shape of parents should match\"\n",
    "\n",
    "        weights_mask = torch.FloatTensor(parent1.shape).uniform_(0, 1) <= p\n",
    "        new_chromosome = parent1 * weights_mask + parent2 * weights_mask.logical_not()\n",
    "        \n",
    "        child = GeneticTiedAutoEncoder(self.shape_list, self.nonlinearity)\n",
    "        child.state_dict()[layer_key] = weights_mask  \n",
    "        return child\n",
    "        \n",
    "    @torch.no_grad()      \n",
    "    def mutation(self, layer_key, p):\n",
    "        chromosome = self.state_dict()[layer_key]\n",
    "        weights_mask = torch.FloatTensor(chromosome.shape).uniform_(0, 1) > p \n",
    "        self.state_dict()[layer_key] = chromosome * weights_mask  \n",
    "        \n",
    "def train_genetic_model(shape_list, pop_size, generations, prev_weights = {}, finetune_epoch=3, finetune_lr=0.01 , loss_fn=F.mse_loss):    \n",
    "    \n",
    "    #Generate choromosomes\n",
    "    print(\"\\nGenerated {0} models with {1} layer size! \".format(pop_size, shape_list))\n",
    "    models = [GeneticTiedAutoEncoder(shape_list, nonlinearity =torch.relu) for i in range(pop_size)]\n",
    "   \n",
    "    #Load prevoius layer weights\n",
    "    print()\n",
    "    if prev_weights != {}:\n",
    "        for model in models:\n",
    "             model.load_state_dict(prev_weights, strict=False)\n",
    "        shapes = []\n",
    "        for key_weight in prev_weights:\n",
    "            shapes.append(prev_weights[key_weight].shape)\n",
    "        print(\"\\nLoaded prevoius layer weights with shape {0}\".format(shapes))\n",
    "    \n",
    "    layer_key = next(reversed(models[0].state_dict())) #last layer key\n",
    "    print(\"\\nTraining {0} with shape of {1} : \".format(layer_key, models[0].state_dict()[layer_key].shape))\n",
    "    \n",
    "    for g in range(generations):     \n",
    "        print(\"\\nGeneration {0}: \\n\".format(g+1))\n",
    "        print(\"Calculating fitness for each chromosome...\")\n",
    "        #fitness\n",
    "        fitness = []\n",
    "        for model in models:\n",
    "            fitness.append( 1/evaluate_loss(model, train_loader, device))\n",
    "\n",
    "        #Select 5 best models (/choromosomes)\n",
    "        fit_arg = np.argsort(fitness) \n",
    "        selected_models = [models[f] for f in fit_arg[:pop_size//2]]\n",
    "        print(\"Selected {0} Top best chromosomes\".format(pop_size//2))\n",
    "        \n",
    "\n",
    "        #finetune selected models\n",
    "        print(\"Finetuning selected models...\\n\")\n",
    "        for model in selected_models:\n",
    "            #freeze network except the chromosome layer\n",
    "            for name, param in model.named_parameters():\n",
    "                if name == layer_key:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            #train the model\n",
    "            optimizer = optim.Adadelta(model.parameters(), lr=finetune_lr)\n",
    "            for epoch in range(1, finetune_epoch+1):\n",
    "                train(model, device, train_loader, optimizer, epoch, loss_fn)\n",
    "            \n",
    "\n",
    "        #cross over and mutation    \n",
    "        print(\"Generate {0} other chromosomes with Cross-Over and Mutation\\n\".format( pop_size//2))\n",
    "        for _ in range(pop_size//2):\n",
    "            mom_idx = np.random.randint(low=0, high=pop_size//2)\n",
    "            dad_idx = np.random.randint(low=0, high=pop_size//2)\n",
    "            child = selected_models[mom_idx].crossover(selected_models[dad_idx],layer_key, p=0.8)\n",
    "            child.mutation(layer_key, p=0.01)\n",
    "            selected_models.append(child)\n",
    "        models = selected_models\n",
    "        \n",
    "    fitness = []    \n",
    "    print(\"Selecting best chromosome as answer...\")\n",
    "    #fitness\n",
    "    for model in models:\n",
    "        fitness.append( 1/evaluate_loss(model, train_loader, device))\n",
    "    fit_arg = np.argsort(fitness) \n",
    "    best_model = models[fit_arg[-1]]\n",
    "    print(\"Finished\")\n",
    "    return best_model\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 10 models with [784, 500] layer size! \n",
      "\n",
      "\n",
      "Training layers.0.param with shape of torch.Size([500, 784]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n"
     ]
    }
   ],
   "source": [
    "shape_list = [784, 500, 200, 100]\n",
    "shape_list = [784, 500]\n",
    "pop_size = 10 \n",
    "generations = 2\n",
    "finetune_epoch = 0\n",
    "finetune_lr = 0.01\n",
    "prev_weights = {}\n",
    "\n",
    "model = train_genetic_model(shape_list, pop_size, generations, prev_weights, finetune_epoch, finetune_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerwise_genetic_train(shape_list, pop_size, generations, finetune_epoch=3, finetune_lr=0.01 , loss_fn=F.mse_loss):    \n",
    "    current_shape_list = []\n",
    "    weight_state_dict = {}\n",
    "\n",
    "    for layer_shape in shape_list:\n",
    "        current_shape_list.append(layer_shape)\n",
    "        if len(current_shape_list) < 2:\n",
    "            continue  \n",
    "        model = train_genetic_model(current_shape_list, pop_size, generations, weight_state_dict, finetune_epoch, finetune_lr , loss_fn)\n",
    "        weight_state_dict = model.state_dict()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 10 models with [784, 20] layer size! \n",
      "\n",
      "\n",
      "Training layers.0.param with shape of torch.Size([20, 784]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n",
      "\n",
      "Generated 10 models with [784, 20, 10] layer size! \n",
      "\n",
      "\n",
      "Loaded prevoius layer weights with shape [torch.Size([20, 784])]\n",
      "\n",
      "Training layers.1.param with shape of torch.Size([10, 20]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n",
      "\n",
      "Generated 10 models with [784, 20, 10, 5] layer size! \n",
      "\n",
      "\n",
      "Loaded prevoius layer weights with shape [torch.Size([20, 784]), torch.Size([10, 20])]\n",
      "\n",
      "Training layers.2.param with shape of torch.Size([5, 10]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n",
      "\n",
      "Generated 10 models with [784, 20, 10, 5, 1] layer size! \n",
      "\n",
      "\n",
      "Loaded prevoius layer weights with shape [torch.Size([20, 784]), torch.Size([10, 20]), torch.Size([5, 10])]\n",
      "\n",
      "Training layers.3.param with shape of torch.Size([1, 5]) : \n",
      "\n",
      "Generation 1: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "\n",
      "Generation 2: \n",
      "\n",
      "Calculating fitness for each chromosome...\n",
      "Selected 5 Top best chromosomes\n",
      "Finetuning selected models...\n",
      "\n",
      "Generate 5 other chromosomes with Cross-Over and Mutation\n",
      "\n",
      "Selecting best chromosome as answer...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "shape_list = [784, 20, 10 , 5 , 1]\n",
    "pop_size = 10 \n",
    "generations = 2\n",
    "finetune_epoch = 0\n",
    "finetune_lr = 0.01\n",
    "\n",
    "model = layerwise_genetic_train(shape_list, pop_size, generations, finetune_epoch, finetune_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneticTiedAutoEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): TiedLinearLayer()\n",
       "    (1): TiedLinearLayer()\n",
       "    (2): TiedLinearLayer()\n",
       "    (3): TiedLinearLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1668869734087,
     "user": {
      "displayName": "Ghasedak Mohajer",
      "userId": "00662349856745641641"
     },
     "user_tz": -210
    },
    "id": "aw82dI0sM-xE",
    "outputId": "0f80f5c6-9471-4f65-cbcd-afd971d2706c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_sample = train_dataset[2][0]\n",
    "plt.imshow(data_sample.squeeze())\n",
    "plt.show()\n",
    "encoded_feats, reconstructed_output = model(data_sample)\n",
    "# reconstructed_output = model(data_sample)\n",
    "plt.imshow(reconstructed_output.detach().numpy().reshape(28,28) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5sJXR6lRTwdohVK8osUWX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
